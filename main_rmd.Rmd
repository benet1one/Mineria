---
title: "Song Popularity Prediction"
subtitle: "An Analysis Using Data Mining Techniques"
author: |
  Garcia Garcia, Bernat  
  Maria Montés, Iker  
  Rota, Davide  
  Tobella Jacomet, Pol  
  
date: "2025-10-02"
output:
  pdf_document: 
    latex_engine: xelatex
header-includes:
- \usepackage{graphicx}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhead[R]{}
- \fancyhead[L]{}
- \fancyhead[C]{\includegraphics[height=1.5cm]{Logos.png}}
- \fancyfoot[R]{}
- \fancyfoot[C]{\thepage}
- \renewcommand{\headrulewidth}{0.7pt}
- \setlength{\headheight}{48pt}
- \addtolength{\topmargin}{-25pt}
- \usepackage{titling}
- \usepackage{graphicx}
- \pretitle{\vspace{3cm}\begin{center}\LARGE}
- \posttitle{\vspace{0.5cm}\end{center}}
- \preauthor{\begin{center}\large}
- \postauthor{\end{center}}
- \predate{\begin{center}}
- \postdate{\vspace{3cm}\end{center}\begin{center}\includegraphics[width=8cm]{Logos.png}\end{center}}
---

\newpage
\tableofcontents
\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,warning = FALSE,message = FALSE)
options(tinytex.verbose = TRUE)
```

```{r}
#### Libraries that might be useful  ####

# library(clustMixType)
# library(tidyr)
# library(dplyr)
# library(visdat)
# library(GGally)
# library(ggplot2)
# library(ggpubr)
# library(purrr)
# library(corrplot)
# library(DMwR2)
# library(knitr)
# library(tinytex)
# library(cowplot)
# library(cluster)
# library(fpc)
# library(factoextra)
# library(dendextend)
# library(grid)
# library(sjPlot)
# library(inspectdf)
# library(isotree)
# library(reticulate)
# library(lubridate)
# library(NbClust)
# library(FactoMineR)
# library(modeest)
# library(FactoClass)
# library(broom)
# library(gridExtra)
```

# Introduction

In this paper we will analyze data related to spotify tracks, with the objective of determining a way to predict a song/track popularity in the site through information related to that track. ***Needs to be expanded a bit probably***


# Motivation

...

# Metadata

Our dataset consists of 13186 imputs of spotify tracks with 15 variables. From those, 3 are qualitative variables while 12 are quantitative variables.

***Probably some more explanation needed***

## Data source

The data has been obtained from the file *"train.csv"*. This file contains information related to tracks of Spotify, openly shared on the net. The data originally comes from the platform Kaggle, specifically from the contest *Predicción de la Popularidad de Canciones*.  

*Disclaimer: This data will not be used to train machine learning or AI models, as per the Policy Note of Spotify.*

\newpage
# Overview of the Data

## Qualitative variables

· **Audio mode**: Mode indicates the modality (*major or minor*) of a track, the type of scale from which its melodic content is derived.
Major is represented by 1 and minor is 0.
Example: 0

· **Key**: The key the track is in.
Integers map to pitches using standard Pitch Class notation.
E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on.
If no key was detected, the value is -1.
Range: -1..11 Example: 9

· **Time signature**: An estimated time signature.
The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).
The time signature ranges from 3 to 7 indicating time signatures of "3/4", to "7/4".
Range: 3 - 7 Example: 4

## Quantitative variables

### Relative/Ratio variables (0..1)

· **Liveness**: Detects the presence of an audience in the recording.
Higher liveness values represent an increased probability that the track was performed live.
*A value above 0.8 provides strong likelihood that the track is live.* Example: 0.0866

· **Danceability**: Danceability describes how suitable a track is for dancing *based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity*.
A value of 0.0 is least danceable and 1.0 is most danceable.
Example: 0.585

· **Audio valence**: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track.
*Tracks with high valence sound more positive* (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).
Example: 0.428

· **Energy**: Energy is a measure from 0.0 to 1.0 and represents a perceptual *measure of intensity and activity*.
Typically, energetic tracks feel *fast, loud, and noisy*.
For example, death metal has high energy, while a Bach prelude scores low on the scale.
Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.
Example: 0.842

· **Acousticness**: A confidence measure from 0.0 to 1.0 of whether the track is acoustic.
*1.0 represents high confidence the track is acoustic*.
Example: 0.00242

· **Speechiness**: Speechiness detects the presence of *spoken words in a track*.
The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value.
*Values above 0.66 describe tracks that are probably made entirely of spoken words*.
Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music.
Values below 0.33 most likely represent music and other non-speech-like tracks.
Example: 0.0556

· **Instrumentalness**: Predicts whether a track contains no vocals.
"Ooh" and "aah" sounds are treated as instrumental in this context.
Rap or spoken word tracks are clearly "vocal".
*The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content*.
Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.
Example: 0.00686

· **Song popularity**: Objective variable, which describes the popularity of the song.
The popularity of a track is a value between 0 and 100, with 100 being the most popular.
Example: 69

### Absolute variables

· **ID**: A count, from 1 to 13186 ***Not spotify ID***

· **Loudness**: The overall loudness of a track in decibels (dB).
Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks.
Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude).
*Values typically range between -60 and 0 db*.
Example: -5.883

· **Song duration (ms)**: The duration of the track in milliseconds.
Example: 237040

· **Tempo**: The overall estimated tempo of a track in beats per minute (BPM).
In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.
Example: 118.211

\newpage

## The data

In this section we show a summary of our data
```{r}

#My own (Pol) wd, not standard
setwd("C:/Users/Sobretaula/Documents/GitHub/Mineria")
songs<-read.csv("data/train.csv")
summary(songs)

```

```